# Example config for C++ (non-python) gtp bot

# RUNNING ON AN ONLINE SERVER OR IN A REAL TOURNAMENT OR MATCH:
# If you plan to do so, you may want to read through the "Rules" section
# below carefully for proper handling of komi and handicap games and end-of-game cleanup
# and various other details.

# NOTES ABOUT PERFORMANCE AND MEMORY USAGE:
# You will likely want to tune one or more the following:
#
# numSearchThreads:
# The number of CPU threads to use. If your GPU is powerful, it can actually be much higher than
# the number of cores on your processor because you will need many threads to feed large enough
# batches to make good use of the GPU.
#
# nnMaxBatchSize:
# The maximum GPU batch size. Should often be at least as large as numSearchThreads.
# Larger won't do anything, but also won't hurt except use a little bit more GPU memory.
# Smaller can be fine if you have more than one GPU, since the GPUs will be sharing the work
# of servicing the CPU threads.
#
# cudaUseFP16 and cudaUseNHWC:
# These have a good chance of improving peformance at larger threads/batch sizes if
# you are using the CUDA implementation with an NVIDIA GPU with FP16 tensor cores.
#
# nnCacheSizePowerOfTwo:
# This controls the NN Cache size, which is the primary RAM/memory use.
# Each neural net entry takes very approximately 1.5KB, except when using whole-board
# ownership/territory visualizations, each entry will take very approximately 3KB.
# The number of entries is (2 ** nnCacheSizePowerOfTwo), for example 2 ** 18 = 262144.
# Increase this if you don't mind the memory use and want better performance
# for searches with tens of thousands of visits or more (due to birthday paradox
# it can start mattering well before cache actually fills entirely up).
# Decrease this if you want to limit memory usage.
#
# OTHER NOTES:
# If you have more than one GPU, take a look at "OpenCL GPU settings" or "CUDA GPU settings" below.
#
# If using OpenCL, you will want to verify that KataGo is picking up the correct device!
# (e.g. some systems may have both an Intel CPU OpenCL and GPU OpenCL, if KataGo appears to pick
# the wrong one, you correct this by specifying "openclGpuToUse" below).
#
# You may also want to adjust "maxVisits", "ponderingEnabled", "resignThreshold", and possibly
# other parameters depending on your intended usage.


# Logs------------------------------------------------------------------------------------

# Where to output log?
logFile = gtp.log
# Logging options
logAllGTPCommunication = true
logSearchInfo = true
logToStderr = false

# KataGo will display some info to stderr on GTP startup
# Uncomment this to suppress that and remain silent
# startupPrintMessageToStderr = false

# Chat some stuff to stderr, for use in things like malkovich chat to OGS.
# ogsChatToStderr = true

# Configure the maximum length of analysis printed out by lz-analyze and other places.
# Controls the number of moves after the first move in a variation.
# analysisPVLen = 9

# Report winrates for chat and analysis as (BLACK|WHITE|SIDETOMOVE).
# Default is SIDETOMOVE, which is what tools that use LZ probably also expect
# reportAnalysisWinratesAs = SIDETOMOVE

# Default rules------------------------------------------------------------------------------------
# See https://lightvector.github.io/KataGo/rules.html for a description of the rules.
# These rules are defaults and can be changed mid-run by several custom GTP commands.
# See https://github.com/lightvector/KataGo/blob/master/docs/GTP_Extensions.md for those commands.

# koRule = SIMPLE       # Simple ko rules (triple ko = no result)
koRule = POSITIONAL     # Positional superko
# koRule = SITUATIONAL  # Situational superko

scoringRule = AREA         # Area scoring
# scoringRule = TERRITORY  # Territory scoring (uses a sort of special computer-friendly territory ruleset)

taxRule = NONE    # All surrounded empty points are scored
# taxRule = SEKI  # Eyes in seki do NOT count as points
# taxRule = ALL   # All groups are taxed up to 2 points for the two eyes needed to live

multiStoneSuicideLegal = true  #Is multiple-stone suicide legal? (Single-stone suicide is always illegal).

hasButton = false # Set to true when area scoring to award 0.5 points to the first pass.

whiteHandicapBonus = 0      # In handicap games, give white no compensation for black's handicap stones (Tromp-taylor, NZ, JP)
# whiteHandicapBonus = N-1  # In handicap games, give white N-1 points for black's handicap stones (AGA)
# whiteHandicapBonus = N    # In handicap games, give white N points for black's handicap stones (Chinese)

# Bot behavior---------------------------------------------------------------------------------------

# Resignation -------------

# Resignation occurs if for at least resignConsecTurns in a row,
# the winLossUtility (which is on a [-1,1] scale) is below resignThreshold.
allowResignation = true
resignThreshold = -0.98
resignConsecTurns = 3

# Handicap -------------

# Assume that if black makes many moves in a row right at the start of the game, then the game is a handicap game.
# This is necessary on some servers and for some GUIs and also when initializing from many SGF files, which may
# set up a handicap games using repeated GTP "play" commands for black rather than GTP "place_free_handicap" commands.
# However, it may also lead to incorrect understanding of komi if whiteHandicapBonus is used and a server does NOT
# have such a practice.
# Defaults to true! Uncomment and set to false to disable this behavior.
# assumeMultipleStartingBlackMovesAreHandicap = true

# Uncomment these and set playoutDoublingAdvantage to a value from -2.0 to 2.0 to vary KataGo's aggression level, useful for handicap games.
# Negative makes KataGo behave as if it thinks it is much weaker than the opponent, preferring to play defensively.
# May backfire due to giving up too many points.
# Positive makes KataGo behave as if it thinks it is much stronger than the opponent, preffering to play aggressively.
# May backfire due to slightly overplaying if the opponent is strong enough to actually punish.
# playoutDoublingAdvantage = 0.0
# playoutDoublingAdvantagePla = WHITE  # Should be set to the side that KataGo will be playing

# Uncomment these two lines instead to make KataGo do something dynamic with playoutDoublingAdvantage based on
# the number of handicap stones and whether it's caught up enough.
# dynamicPlayoutDoublingAdvantageCapPerOppLead = 0.04
# playoutDoublingAdvantagePla = WHITE  # Must be set to the side that KataGo will be playing

# Passing and cleanup -------------

# Make the bot never assume that its pass will end the game, even if passing would end and "win" under Tromp-Taylor rules.
# Usually this is a good idea when using it for analysis or playing on servers where scoring may be implemented non-tromp-taylorly.
# Defaults to true! Uncomment and set to false to disable this.
# conservativePass = true

# When playing under territory scoring, encourage the bot to fill dame before passing.
# This is NOT absolutely guaranteed to work, and possibly in some rare pathological situations will make the bot
# play a bad move, losing points. However, it also acts as a safeguard against things like a situation when the opponent must
# eventually make a protective move and lose 1 point, where the bot might otherwise assume that the score would be counted as such,
# yet without filling the dame to force the opponent to actually make the move.
# Defaults to true! Uncomment and set to false to disable this.
# fillDameBeforePass = true

# When using territory scoring, self-play games continue beyond two passes with special cleanup
# rules that may be confusing for human players. This option prevents the special cleanup phases from being
# reachable when using the bot for GTP play.
# Defaults to true! Uncomment and set to false if you want KataGo to be able to enter special cleanup.
# For example, if you are testing it against itself, or against another bot that has precisely implemented the rules
# documented at https://lightvector.github.io/KataGo/rules.html
# preventCleanupPhase = true


# Search limits-----------------------------------------------------------------------------------

# If provided, limit maximum number of root visits per search to this much. (With tree reuse, visits do count earlier search)
maxVisits = 1000
# If provided, limit maximum number of new playouts per search to this much. (With tree reuse, playouts do not count earlier search)
# maxPlayouts = 1000
# If provided, cap search time at this many seconds (search will still try to follow GTP time controls)
# maxTime = 60

# Ponder on the opponent's turn?
ponderingEnabled = false

# Same limits but for ponder searches if pondering is enabled
# maxVisitsPondering = 1000
# maxPlayoutsPondering = 1000
# maxTimePondering = 60

# Number of seconds to buffer for lag for GTP time controls
lagBuffer = 1.0

# Number of threads to use in search
numSearchThreads = 1

# Play a little faster if the opponent is passing, for friendliness
searchFactorAfterOnePass = 0.50
searchFactorAfterTwoPass = 0.25
# Play a little faster if super-winning, for friendliess
searchFactorWhenWinning = 0.40
searchFactorWhenWinningThreshold = 0.95

# GPU Settings-------------------------------------------------------------------------------

# Maximum number of positions to send to GPU at once. Note that you will also need to increase numSearchThreads
# to make use of this, as every thread in KataGo is synchronous, so with 1 thread max batch will only be 1 anyways.
nnMaxBatchSize = 16
# Cache up to 2 ** this many neural net evaluations in case of transpositions in the tree.
nnCacheSizePowerOfTwo = 19
# Size of mutex pool for nnCache is 2 ** this
nnMutexPoolSizePowerOfTwo = 15
# Randomize board orientation when running neural net evals?
nnRandomize = true
# If provided, force usage of a specific seed for nnRandomize instead of randomizing
# nnRandSeed = abcdefg

# How many threads should there be to feed positions to the neural net?
# Server threads are indexed 0,1,...(n-1) for the purposes of the below GPU settings arguments
# that specify which threads should use which GPUs.
# NOTE: This parameter is probably ONLY useful if you have multiple GPUs, since each GPU will need a thread.
# If you're tuning single-GPU performance, use numSearchThreads instead.
numNNServerThreadsPerModel = 1

# CUDA GPU settings--------------------------------------
# These only apply when using CUDA as the backend for inference.
# (For GTP, we only ever have one model, when playing matches, we might have more than one, see match_example.cfg)

# Default behavior tries to guess the 'best' GPU or device
# You will want to uncomment and adjust one or more of these lines to take advantage of a multi-gpu machine
# cudaDeviceToUse = 0 #use device 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# cudaDeviceToUseModel0 = 3 #use device 3 for model 0 for all threads unless otherwise specified per-thread for this model
# cudaDeviceToUseModel1 = 2 #use device 2 for model 1 for all threads unless otherwise specified per-thread for this model
# cudaDeviceToUseModel0Thread0 = 3 #use device 3 for model 0, server thread 0
# cudaDeviceToUseModel0Thread1 = 2 #use device 2 for model 0, server thread 1

# Uncomment these on NVIDIA devices with FP16 tensor cores for probably a speedup, at the cost of introducing some precision loss in the nn calculation.
# cudaUseFP16 = true
# cudaUseNHWC = true

# OpenCL GPU settings--------------------------------------
# These only apply when using OpenCL as the backend for inference.
# (For GTP, we only ever have one model, when playing matches, we might have more than one, see match_example.cfg)

# Default behavior tries to guess the 'best' GPU or device
# You will want to uncomment and adjust one or more of these lines to take advantage of a multi-gpu machine
# openclDeviceToUse = 0 #use device 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# openclDeviceToUseModel0 = 3 #use device 3 for model 0 for all threads unless otherwise specified per-thread for this model
# openclDeviceToUseModel1 = 2 #use device 2 for model 1 for all threads unless otherwise specified per-thread for this model
# openclDeviceToUseModel0Thread0 = 3 #use device 3 for model 0, server thread 0
# openclDeviceToUseModel0Thread1 = 2 #use device 2 for model 0, server thread 1

# Uncomment to tune OpenCL for every board size separately, rather than only the largest possible size
# openclReTunePerBoardSize = true

# Root move selection and biases------------------------------------------------------------------------------

# If provided, force usage of a specific seed for various things in the search instead of randomizing
# searchRandSeed = hijklmn

# Temperature for the early game, randomize between chosen moves with this temperature
chosenMoveTemperatureEarly = 0.5
# Decay temperature for the early game by 0.5 every this many moves, scaled with board size.
chosenMoveTemperatureHalflife = 19
# At the end of search after the early game, randomize between chosen moves with this temperature
chosenMoveTemperature = 0.10
# Subtract this many visits from each move prior to applying chosenMoveTemperature
# (unless all moves have too few visits) to downweight unlikely moves
chosenMoveSubtract = 0
# The same as chosenMoveSubtract but only prunes moves that fall below the threshold, does not affect moves above
chosenMovePrune = 1

# Use dirichlet noise for the root node policy?
rootNoiseEnabled = false
# Dirichlet noise alpha is set to this divided by number of legal moves. 10.83 produces an alpha of 0.03 on an empty 19x19 board.
rootDirichletNoiseTotalConcentration = 10.83
# Proportion of root policy that is noise
rootDirichletNoiseWeight = 0.25

# Number of symmetries to sample (WITH replacement) and average at the root
rootNumSymmetriesToSample = 1

# Using LCB for move selection?
useLcbForSelection = true
# How many stdevs a move needs to be better than another for LCB selection
lcbStdevs = 5.0
# Only use LCB override when a move has this proportion of visits as the top move
minVisitPropForLCB = 0.15

# Internal params------------------------------------------------------------------------------

# Scales the utility of winning/losing
winLossUtilityFactor = 1.0
# Scales the utility for trying to maximize score
staticScoreUtilityFactor = 0.10
dynamicScoreUtilityFactor = 0.30
# Adjust dynamic score center this proportion of the way towards zero, capped at a reasonable amount.
dynamicScoreCenterZeroWeight = 0.20
dynamicScoreCenterScale = 0.75
# The utility of getting a "no result" due to triple ko or other long cycle in non-superko rulesets (-1 to 1)
noResultUtilityForWhite = 0.0
# The number of wins that a draw counts as, for white. (0 to 1)
drawEquivalentWinsForWhite = 0.5

# Exploration constant for mcts
cpuctExploration = 0.9
cpuctExplorationLog = 0.6
# FPU reduction constant for mcts
fpuReductionMax = 0.2
rootFpuReductionMax = 0.1
# Use parent average value for fpu base point instead of point value net estimate
fpuUseParentAverage = true
# Amount to apply a downweighting of children with very bad values relative to good ones
valueWeightExponent = 0.5
# Slight incentive for the bot to behave human-like with regard to passing at the end, filling the dame,
# not wasting time playing in its own territory, etc, and not play moves that are equivalent in terms of
# points but a bit more unfriendly to humans.
rootEndingBonusPoints = 0.5
# Make the bot prune useless moves that are just prolonging the game to avoid losing yet
rootPruneUselessMoves = true

# How big to make the mutex pool for search synchronization
mutexPoolSize = 8192
# How many virtual losses to add when a thread descends through a node
numVirtualLossesPerThread = 1
