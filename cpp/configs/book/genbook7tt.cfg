# Example config for genbook command for 7x7, Tromp-taylor-like rules.
# Note that KataGo's implementation has one tiny difference/optimization - if a stone is "pass-dead"
# (i.e. surrounded by pass-alive groups and cannot live even with arbitrarily many moves in a row, it will be scored dead without needing to capture it).

# Logging----------------------------------------------------------------------------
logSearchInfo = false

# Rules------------------------------------------------------------------------------------
rulesLabel = Using Tromp-Taylor rules, komi 9
rulesLink = https://tromp.github.io/go.html
rules = tromp-taylor
komi = 9
boardSizeX = 7
boardSizeY = 7

numGameThreads = 8
numToExpandPerIteration = 64

# Book params----------------------------------------------------------------------------
# Book always expands the positions in the tree with the minimum cost.
# Winloss is winrate except scaled to [-1,1]

errorFactor = 1.5                     # For UCB params below, use mean + many standard deviations.
costPerMove = 0.45                    # Add this much cost per move in a variation.
costPerUCBWinLossLoss = 4.50          # Add this much cost per winloss that a move's UCB is than the top UCB move.
costPerUCBWinLossLossPow3 = 0.75      # Same, but focused on the tails (i.e. 0.95 -> 0.9 is a costlier gap than 0.6 -> 0.55).
costPerUCBWinLossLossPow7 = 0.75      # Same, but even more focused on the tails.
costPerUCBScoreLoss = 0.75            # Add this much cost per score that a move's UCB is worse than the top UCB move.
costPerLogPolicy = 0.75               # Add this much cost per log policy.
costPerMovesExpanded = 0.25           # Add this much cost per move already tried at this node.
costPerSquaredMovesExpanded = 0.05    # Add this much cost per move already tried squared.
costWhenPassFavored = 3.5             # Add this much cost when pass seems to be a good move. Helps reeduce pointless search of game-over positions.
bonusPerWinLossError = 1.0            # Amount to reduce cost per standard deviation of winloss error.
bonusPerScoreError = 0.03             # Amount to reduce cost per standard deviation of score error.
bonusPerSharpScoreDiscrepancy = 0.15  # Amount to reduce cost per point that score estimate and sharp score estimate disagree
bonusPerExcessUnexpandedPolicy = 2.0  # Amount to reduce cost per policy pass that has not been expanded at a node.
bonusForWLPV1 = 0.03                  # Proportion to reduce cost for searching moves that appear to be the best move and have a winrate of near 50%.
bonusForWLPV2 = 0.15                  # Proportion to reduce cost for searching moves that appear to be the best move and have a winrate of near 25% or 75%.
bonusForBiggestWLCost = 0.20          # Proportion to reduce cost based on the largest winloss cost in a variation. (explore variations with *one* big mistake, but not more than one)
bonusPerUnexpandedBestWinLoss = 1.5   # Bonus to add when the best winloss at a node is currently a move barely explored.
earlyBookCostReductionFactor = 0.0    # Set between 0 and 1, subtracts that proportion of the cost of early bad moves. (explore more deliberate bad openings).
earlyBookCostReductionLambda = 0.5    # earlyBookCostReductionFactor is multiplied by earlyBookCostReductionFactor ** turnNumber so it mostly affects only early moves.
scoreLossCap = 3.0                    # Cap costs due to UCBScoreLoss at this much.
utilityPerScore = 0.1                 # For exporting book to html for sorting moves, and for minor internal adjustments to reduce cost to good moves.
policyBoostSoftUtilityScale = 0.04    # If a low-policy move is roughly this amount better than a high-policy move in utility, don't penalize it so much.
utilityPerPolicyForSorting = 0.02     # For exporting a book to html for sorting moves.
sharpScoreOutlierCap = 10000          # Cap on score magnitude.

# Guarantees that long cycles <= this length (and maybe some longer ones) are handled correctly.
# Do NOT change once a book has started being generated.
repBound = 9

# Misc Behavior --------------------
conservativePass = false
rootSymmetryPruning = true

# Search limits-----------------------------------------------------------------------------------

maxVisits = 15000
numSearchThreads = 30

# You can use parameters like these if you want to copy entire variations from the search into the book
# instead of only the result at the root of the search. It can be a little more computationally efficient
# if you do this with more visits per search.
# maxVisits = 150000
# minTreeVisitsToRecord = 15000
# maxVisitsForReExpansion = 30000
# maxDepthToRecord = 12
# maxVisitsForLeaves = 7500

nnCacheSizePowerOfTwo = 23
nnMutexPoolSizePowerOfTwo = 17

cudaDeviceToUse = 0

# Params------------------------------------------------------------------------------
chosenMoveTemperatureEarly = 0.0
chosenMoveTemperature = 0.0

rootNumSymmetriesToSample = 8

useLcbForSelection = true
lcbStdevs = 6.0
minVisitPropForLCB = 0.20

# Slightly wider than normal search parameters, to encourage not missing any good moves.
wideRootNoise = 0.05
cpuctExploration = 1.25
cpuctExplorationLog = 0.5
valueWeightExponent = 0.0

# Used when the book is explictly trying to explore and accuracy doesn't matter much.
wideRootNoiseBookExplore = 0.10
cpuctExplorationLogBookExplore = 1.0

rootPruneUselessMoves = false

useUncertainty = true
uncertaintyExponent = 1.0
uncertaintyCoeff = 0.25
