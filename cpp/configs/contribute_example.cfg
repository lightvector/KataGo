
# Be careful not to share any config files where you have entered your password.

serverUrl = https://katagotraining.org/
username = Fill in your username here
password = Fill in your password here
# If your password has hash signs or trailing spaces, you can also surround the password with double quotes, like this.
# Within double quotes, backslashes are escape characters.
# password = "Fill in your password here"

# How many games should KataGo play at once? For good GPUs, putting too small a number here will be *very* inefficient.
# For absolute-top-tier GPUs, try numbers like 32, 40, 64, etc.
# For modern good middle-tier GPUs, you can try numbers like 8 or 16.
# For very old or weak GPUs, or if you want KataGo to put less load on your system, try 4.
maxSimultaneousGames = Fill in a number here

# Set to true if you want one of KataGo's games to be streamed to a text file, so you can watch.
# Follow in a separate shell with a command like the following:
# Linux: "tail -f watchgame.txt"
# Windows Powershell: "Get-Content .\watchgame.txt -Tail 50 -Wait"
watchOngoingGameInFile = false
watchOngoingGameInFileName = watchgame.txt

# If you use an https proxy to connect to the internet, set these to the host and port of your proxy.
# proxyHost = HOSTNAME
# proxyPort = 1234

# Special-purpose options. Most users should not need to adjust these.
# onlyPlayRatingMatches = false
# maxRatingMatches = 1
# disablePredownloadLoop = false
# warnTaskUnusedKeys = false

# KataGo will only use one GPU by default. You can edit the below if you have multiple GPUs and want to use them all.


# TO USE MULTIPLE GPUS:
# Set this to the number of GPUs you have and/or would like to use.
# **AND** if it is more than 1, uncomment the appropriate CUDA or OpenCL section below.
# numNNServerThreadsPerModel = 1


# TENSORRT GPU settings--------------------------------------
# These only apply when using the TENSORRT version of KataGo.

# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0
# trtDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):
# trtDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# trtDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1

# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):
# trtDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# trtDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1
# trtDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2

# You can probably guess the pattern if you have four, five, etc. GPUs.


# CUDA GPU settings--------------------------------------
# These only apply when using the CUDA version of KataGo.

# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0
# cudaDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):
# cudaDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# cudaDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1

# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):
# cudaDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# cudaDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1
# cudaDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2

# You can probably guess the pattern if you have four, five, etc. GPUs.

# KataGo will automatically use FP16 or not based on the compute capability of your NVIDIA GPU. If you
# want to try to force a particular behavior though you can uncomment these lines and change them
# to "true" or "false". E.g. it's using FP16 but on your card that's giving an error, or it's not using
# FP16 but you think it should.
# cudaUseFP16 = auto
# cudaUseNHWC = auto


# Metal GPU settings--------------------------------------

# These only apply when using the METAL version of KataGo.

# For one Metal instance: KataGo will automatically use the default device.
# metalDeviceToUse = 0

# For two Metal instance: Uncomment these options, AND set numNNServerThreadsPerModel = 2 above.
# This will create two Metal instances, best overlapping the GPU and CPU execution.
# metalDeviceToUseThread0 = 0
# metalDeviceToUseThread1 = 1

# The pattern continues for additional Metal instances.


# ROCm GPU settings--------------------------------------
# These only apply when using the ROCm version of KataGo.

# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0
# rocmDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):
# rocmDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# rocmDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1

# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):
# rocmDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# rocmDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1
# rocmDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2

# You can probably guess the pattern if you have four, five, etc. GPUs.

# KataGo will automatically use FP16 or not based on the compute capability of your AMD GPU. If you
# want to try to force a particular behavior though you can uncomment these lines and change them
# to "true" or "false". E.g. it's using FP16 but on your card that's giving an error, or it's not using
# FP16 but you think it should.
# rocmUseFP16 = auto
# ROCm does not support NHWC, so this is always false.


# OpenCL GPU settings--------------------------------------
# These only apply when using the OpenCL version of KataGo.

# Uncomment to tune OpenCL for every board size separately, rather than only the largest possible size
# openclReTunePerBoardSize = true

# IF USING ONE GPU: optionally uncomment and change this if the best device to use is guessed incorrectly.
# The default behavior tries to guess the 'best' GPU or device on your system to use, usually it will be a good guess.
# openclDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines and replace X and Y with the device ids of the devices you want to use.
# It might NOT be 0 and 1, some computers will have many OpenCL devices. You can see what the devices are when
# KataGo starts up - it should print or log all the devices it finds.
# (AND also set numNNServerThreadsPerModel above)
# openclDeviceToUseThread0 = X
# openclDeviceToUseThread1 = Y

# IF USING THREE GPUS: Uncomment these three lines and replace X and Y and Z with the device ids of the devices you want to use.
# It might NOT be 0 and 1 and 2, some computers will have many OpenCL devices. You can see what the devices are when
# KataGo starts up - it should print or log all the devices it finds.
# (AND also set numNNServerThreadsPerModel above)
# openclDeviceToUseThread0 = X
# openclDeviceToUseThread1 = Y
# openclDeviceToUseThread2 = Z

# You can probably guess the pattern if you have four, five, etc. GPUs.

# KataGo will automatically use FP16 or not based on testing your GPU during tuning. If you
# want to try to force a particular behavior though you can uncomment this lines and change it
# to "true" or "false". This is a fairly blunt setting - more detailed settings are testable
# by rerunning the tuner with various arguments.
# openclUseFP16 = auto


# Eigen-specific settings--------------------------------------
# These only apply when using the Eigen (pure CPU) version of KataGo.

# This is the number of CPU threads for evaluating the neural net on the Eigen backend.
# It defaults to numSearchThreads.
# numEigenThreadsPerModel = X
