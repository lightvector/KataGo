# Example config for C++ match runner
# This is an example template config for the "match" subcommand of KataGo. e.g:
# ./katago match -config-file configs/match_example.cfg -log-file match.log -sgf-output-dir match_sgfs/
#
# On a good GPU, the match subcommand enables testing of KataGo nets against each other
# or a net against itself with different parameters vastly faster than anything
# else, because multiple games can share GPU batching.
#
# Beware however of using this to test differing numbers of threads or test time-based search limits.
# Because many games will be run simultaneously, they will compete from each other for compute power,
# and although the total will run much faster than if you had run them one by one, you might also get
# substantially different results not reflective of the strength of a configuration when run in a real
# match setting, on a machine by itself. For fixed numbers of visits or playouts instead of fixed time,
# and with numSearchThreads = 1, there should be no problem though, because then the compute time has
# no influence on the result of the computation.
#
# See gtp config for descriptions of most of these params.
#
# For almost any parameter in this config that is related to a bot, rather than to the match as a whole
# (so, visits, search parameters, model files, etc. but NOT the rules, max games, log info, etc)
# you can specify them differentially between different bots by appending the index of the bot.
# For example, if you were testing different numbers of visits, you could try:
#
# numBots = 3
# botName0 = lowVisits
# botName1 = midVisits
# botName2 = highVisits
#
# maxVisits0 = 100
# maxVisits1 = 300
# maxVisits2 = 1000
#
# Or, if you were testing different neural nets, with different search configurations, you could do:
#
# nnModelFile0 = path/to/first/model/file.bin.gz
# nnModelFile1 = path/to/second/model/file.bin.gz
#
# And specify different search parameters for them if you wanted:
# cpuctExploration0 = 1.5
# cpuctExploration1 = 1.3

# Logs------------------------------------------------------------------------------------

logSearchInfo = false
logMoves = false
logGamesEvery = 50
logToStdout = true

# Bots-------------------------------------------------------------------------------------
# For multiple bots, you can specify their names as botName0,botName1, etc.
# If the bots are using different models, specify nnModelFile0, nnModelFile1, etc.

numBots=1
botName=FOO
nnModelFile=PATH_TO_MODEL

# These bots will not play each other, but will still be opponents for other bots
# secondaryBots = 0,1,3
# Only these bots will actually play games. Useful if you have a config file with many more
# bots defined but you want to only selectively enable a few.
# includeBots = 0,2,6

# Specify extra pairings of bots to play.
# extraPairs = 0-4,1-4
# Uncomment and set this to true if you don't want extraPairs to be mirrored by color.
# (i.e. 0-4 should mean 0 plays black and 4 plays white only, rather than having two games with swapped colors).
# extraPairsAreOneSidedBW = false

# Match-----------------------------------------------------------------------------------
numGameThreads=8 # How many games to run in parallel at a time?

numGamesTotal=1000000
maxMovesPerGame=1200

allowResignation = true
resignThreshold = -0.95
resignConsecTurns = 6

# Rules------------------------------------------------------------------------------------
# See https://lightvector.github.io/KataGo/rules.html for a description of the rules.

koRules = SIMPLE,POSITIONAL,SITUATIONAL
scoringRules = AREA,TERRITORY
taxRules = NONE,SEKI,ALL
multiStoneSuicideLegals = false,true
hasButtons = false,true

bSizes = 19,13,9
bSizeRelProbs = 90,5,5

# If you want to specify exact distributions of boards, including rectangles, specify this instead
# of bSizes. E.g. to randomize between a 7x5, a 9x12, and a 10x10 board with probabilities 25%, 25%, 50%:
# bSizesXY=7-5,9-12,10-10
# bSizeRelProbs = 1,1,2

komiAuto = True   # Automatically adjust komi to what the neural nets think are fair
# komiMean = 7.5  # Specify explicit komi
# policyInitAreaProp = 0
# compensateAfterPolicyInitProb = 1.0  # Additionally make komi fair this often after the high-temperature moves.
# policyInitAreaTemperature = 1
handicapProb = 0.0
handicapCompensateKomiProb = 1.0
# numExtraBlackFixed = 3  # When playing handicap games, always use exactly this many extra black moves

# Search limits-----------------------------------------------------------------------------------

maxVisits = 500
# maxPlayouts = 300
# maxTime = 60

numSearchThreads = 1

# GPU Settings-------------------------------------------------------------------------------

nnMaxBatchSize = 32
nnCacheSizePowerOfTwo = 21
nnMutexPoolSizePowerOfTwo = 17
nnRandomize = true


# How many threads should there be to feed positions to the neural net?
# Server threads are indexed 0,1,...(n-1) for the purposes of the below GPU settings arguments
# that specify which threads should use which GPUs.
# NOTE: This parameter is probably ONLY useful if you have multiple GPUs, since each GPU will need a thread.
# If you're tuning single-GPU performance, use numSearchThreads instead.
numNNServerThreadsPerModel = 1


# TENSORRT GPU settings--------------------------------------
# These only apply when using the TENSORRT version of KataGo.

# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0
# trtDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):
# trtDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# trtDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1

# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):
# trtDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# trtDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1
# trtDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2

# You can probably guess the pattern if you have four, five, etc. GPUs.


# CUDA GPU settings--------------------------------------
# For the below, "model" refers to a neural net, from the nnModelFile parameter(s) above.
# cudaGpuToUse = 0 #use gpu 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# cudaGpuToUseModel0 = 3 #use gpu 3 for model 0 for all threads unless otherwise specified per-thread for this model
# cudaGpuToUseModel1 = 2 #use gpu 2 for model 1 for all threads unless otherwise specified per-thread for this model
# cudaGpuToUseModel0Thread0 = 3 #use gpu 3 for model 0, server thread 0
# cudaGpuToUseModel0Thread1 = 2 #use gpu 2 for model 0, server thread 1

# cudaUseFP16 = auto
# cudaUseNHWC = auto


# Metal GPU settings--------------------------------------

# These only apply when using the METAL version of KataGo.

# For one Metal instance: KataGo will automatically use the default device.
# metalDeviceToUse = 0

# For two Metal instance: Uncomment these options, AND set numNNServerThreadsPerModel = 2 above.
# This will create two Metal instances, best overlapping the GPU and CPU execution.
# metalDeviceToUseThread0 = 0
# metalDeviceToUseThread1 = 1

# The pattern continues for additional Metal instances.


# ROCm GPU settings--------------------------------------
# These only apply when using the ROCm version of KataGo.

# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0
# rocmDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):
# rocmDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# rocmDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1

# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):
# rocmDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# rocmDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1
# rocmDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2

# You can probably guess the pattern if you have four, five, etc. GPUs.

# KataGo will automatically use FP16 or not based on the compute capability of your AMD GPU. If you
# want to try to force a particular behavior though you can uncomment these lines and change them
# to "true" or "false". E.g. it's using FP16 but on your card that's giving an error, or it's not using
# FP16 but you think it should.
# rocmUseFP16 = auto
# ROCm does not support NHWC, so this is always false.


# OpenCL GPU settings--------------------------------------
# These only apply when using OpenCL as the backend for inference.
# (For GTP, we only ever have one model, when playing matches, we might have more than one, see match_example.cfg)

# Default behavior is just to always use gpu 0, you will want to uncomment and adjust one or more of these lines
# to take advantage of a multi-gpu machine
# openclGpuToUse = 0 #use gpu 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# openclGpuToUseModel0 = 3 #use gpu 3 for model 0 for all threads unless otherwise specified per-thread for this model
# openclGpuToUseModel1 = 2 #use gpu 2 for model 1 for all threads unless otherwise specified per-thread for this model
# openclGpuToUseModel0Thread0 = 3 #use gpu 3 for model 0, server thread 0
# openclGpuToUseModel0Thread1 = 2 #use gpu 2 for model 0, server thread 1

# Uncomment to tune OpenCL for every board size separately, rather than only the largest possible size
# openclReTunePerBoardSize = true

# openclUseFP16 = auto


# Eigen-specific settings--------------------------------------
# These only apply when using the Eigen (pure CPU) version of KataGo.

# This is the number of CPU threads for evaluating the neural net on the Eigen backend.
# It defaults to numSearchThreads.
# numEigenThreadsPerModel = X


# Root move selection and biases------------------------------------------------------------------------------
# Uncomment and edit any of the below values to change them from their default.
# Values in this section can be specified per-bot as well

chosenMoveTemperatureEarly = 0.60
# chosenMoveTemperatureHalflife = 19
chosenMoveTemperature = 0.20
# chosenMoveSubtract = 0
# chosenMovePrune = 1

# rootNumSymmetriesToSample = 1

# useLcbForSelection = true
# lcbStdevs = 5.0
# minVisitPropForLCB = 0.15

# Internal params------------------------------------------------------------------------------
# Uncomment and edit any of the below values to change them from their default.
# Values in this section can be specified per-bot as well

# winLossUtilityFactor = 1.0
# staticScoreUtilityFactor = 0.10
# dynamicScoreUtilityFactor = 0.30
# dynamicScoreCenterZeroWeight = 0.20
# dynamicScoreCenterScale = 0.75
# noResultUtilityForWhite = 0.0
# drawEquivalentWinsForWhite = 0.5

# cpuctExploration = 0.9
# cpuctExplorationLog = 0.4
# fpuReductionMax = 0.2
# rootFpuReductionMax = 0.1
# fpuParentWeightByVisitedPolicy = true
# valueWeightExponent = 0.25
# rootEndingBonusPoints = 0.5
# rootPruneUselessMoves = true
# subtreeValueBiasFactor = 0.45
# subtreeValueBiasWeightExponent = 0.85
# useGraphSearch = true
# rootPolicyOptimism = 0.2
# policyOptimism = 1.0

# nodeTableShardsPowerOfTwo = 16
# numVirtualLossesPerThread = 1
